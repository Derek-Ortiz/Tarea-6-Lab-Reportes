\# Tarea 6: Next.js Reports Dashboard (PostgreSQL + Views + Docker Compose)

Entrega individual. Este repositorio incluye la base de datos con VIEWS y la app Next.js que consume dichas VIEWS.

## Estructura

- `db/01_schema.sql` - Tablas y constraints
- `db/02_seed.sql` - Datos iniciales
- `db/03_reports_vw.sql` - 5 VIEWS con CTE, HAVING, CASE y Window Functions
- `db/04_roles.sql` - Rol de la app con permisos m√≠nimos
- `db/05_indexes.sql` - √çndices + EXPLAIN ANALYZE
- `db/verify.sql` - Consultas de verificaci√≥n
- `db/00_init.sh` - Script de inicializaci√≥n que inyecta variables de entorno
- `tarea6-dba/` - App Next.js (App Router)
- `docker-compose.yml` - Orquestaci√≥n completa

## Ejecuci√≥n

### Requisitos previos

- **Docker Desktop** (versi√≥n 20.10 o superior)
- **Docker Compose** (versi√≥n 1.29 o superior, o integrado en Docker Desktop)
- **Git** (para clonar el repositorio)

### Opci√≥n 1: Ejecuci√≥n r√°pida (RECOMENDADA)

```bash
# El .env se crea autom√°ticamente desde .env.example si no existe
docker compose up --build
```

A continuaci√≥n, accede a:
- **Aplicaci√≥n**: http://localhost:3000
- **PgAdmin**: http://localhost:5050 (admin@admin.com / admin)

### Opci√≥n 2: Con validaciones previas

```bash
# Ejecutar validaciones primero
bash scripts/validate.sh

# Luego iniciar
docker compose up --build
```

### Opci√≥n 3: Usando el script principal (Linux/Mac)

```bash
chmod +x start.sh
./start.sh
```

### Configurar variables (OPCIONAL)

El proyecto incluye un `.env.example` preconfigurado que funciona correctamente. Si lo necesitas, copia y personaliza:

```bash
cp .env.example .env
# Editar .env si es necesario
```

**Variables importantes:**
- `DB_USER`: Usuario admin de PostgreSQL (default: `postgres`)
- `DB_PASSWORD`: Contrase√±a del admin (default: `postgres123`)
- `DB_NAME`: Nombre de la base de datos (default: `actividad_db`)
- `DB_USER_VW`: Usuario de la aplicaci√≥n (default: `tarea6`)
- `DB_PASSWORD_VW`: Contrase√±a de la aplicaci√≥n (default: `t4r34s313s`)
- `DB_PORT`: Puerto local de PostgreSQL (default: `5433`)
- `DB_PORT_WEB`: Puerto de la aplicaci√≥n (default: `3000`)

‚ö†Ô∏è **IMPORTANTE:** El archivo `.gitattributes` en la ra√≠z es cr√≠tico para que los scripts bash se cloben con saltos de l√≠nea Unix (LF). Si experimentas errores de "bad interpreter", verifica que este archivo existe en el repositorio.



### Flujo de inicializaci√≥n segura

El script `db/00_init.sh` maneja la inyecci√≥n de variables de entorno sin exponer credenciales en los archivos `.sql`:

1. Lee `.env` y carga variables
2. Para `04_roles.sql`, sustituye `current_setting('app_user')` con `DB_USER_VW`
3. Ejecuta todos los scripts `.sql` en orden
4. Crea usuario `tarea6` con permisos SELECT limitados a las 5 vistas

**Beneficio:** Las credenciales nunca se exponen en el repositorio ni en los archivos versionados.

## Evidencia de VIEWS (\dv)

```
 Schema |               Name                | Type |  Owner   
--------+-----------------------------------+------+----------
 public | vista_analisis_desempeno_usuarios | view | postgres 
 public | vista_cat_promedio                | view | postgres 
 public | vista_ordenes_por_status          | view | postgres 
 public | vista_productos_mas_vendidos      | view | postgres 
 public | vista_ranking_usuarios_gastos     | view | postgres 
(5 rows)
```

‚úÖ **5 vistas creadas correctamente con funciones avanzadas:**
- `vista_cat_promedio` - Categor√≠as con COUNT, AVG y ROUND (CASE WHEN)
- `vista_ranking_usuarios_gastos` - ROW_NUMBER() y CASE para niveles
- `vista_ordenes_por_status` - GROUP BY con HAVING
- `vista_productos_mas_vendidos` - Ranking con SUM
- `vista_analisis_desempeno_usuarios` - CTE y Window Functions

## Grain de las VIEWS

### 1. Ranking de Usuarios por Gasto (`vista_ranking_usuarios_gastos`)

**Grain:** 1 fila = 1 usuario
- **M√©tricas:** Total de √≥rdenes, total gastado, promedio por orden, ranking por gasto (RANK), nivel de comprador
- **KPI:** Total gastado acumulado por usuarios frecuentes
- **Par√°metros:** Sin filtros ni paginaci√≥n
- **Funci√≥n avanzada:** ROW_NUMBER() para ranking din√°mico, CASE WHEN para clasificaci√≥n de nivel (Premium/Gold/Silver)

### 2. Promedio de Precios por Categor√≠a (`vista_cat_promedio`)

**Grain:** 1 fila = 1 categor√≠a
- **M√©tricas:** Cantidad de productos, promedio de precio, promedio redondeado a 2 decimales
- **KPI:** An√°lisis de precios por l√≠nea de negocio
- **Par√°metros:** Filtrable por cantidad m√≠nima de productos (WHERE cantidad_productos >= ?)
- **Funci√≥n avanzada:** AVG() con ROUND() y CASE WHEN para m√©tricas condicionales

### 3. √ìrdenes por Estado (`vista_ordenes_por_status`)

**Grain:** 1 fila = 1 status de orden
- **M√©tricas:** Cantidad de √≥rdenes, monto total, porcentaje de distribuci√≥n
- **KPI:** Visibilidad del pipeline de ventas y estado de entregas
- **Par√°metros:** Filtrable por status espec√≠fico
- **Funci√≥n avanzada:** GROUP BY con HAVING, SUM() para agregaciones, c√°lculo de porcentajes

### 4. Productos M√°s Vendidos (`vista_productos_mas_vendidos`)

**Grain:** 1 fila = 1 producto
- **M√©tricas:** Posici√≥n en ranking, cantidad vendida, ingresos totales, nivel de popularidad (Popular/Normal)
- **KPI:** An√°lisis de productos estrella y rendimiento de SKUs
- **Par√°metros:** Filtrable por rango de precios (WHERE precio BETWEEN ? AND ?)
- **Funci√≥n avanzada:** ROW_NUMBER() para ranking de ventas, CASE WHEN para clasificaci√≥n de popularidad

### 5. An√°lisis de Desempe√±o de Usuarios (`vista_analisis_desempeno_usuarios`)

**Grain:** 1 fila = 1 usuario
- **M√©tricas:** √ìrdenes entregadas, √≥rdenes canceladas, monto total, monto acumulado, clasificaci√≥n (Cliente Activo/Inactivo)
- **KPI:** Segmentaci√≥n de clientes por comportamiento de compra
- **Par√°metros:** Sin filtros ni paginaci√≥n directa
- **Funci√≥n avanzada:** CTE (WITH clauses), Window Functions para monto acumulado, CASE WHEN para clasificaci√≥n de cliente

## Performance Evidence (EXPLAIN ANALYZE)

### Evidencia 1: Categor√≠as con Productos

**Comando:**
```sql
EXPLAIN ANALYZE 
SELECT c.nombre, COUNT(p.id) AS cantidad, AVG(p.precio) AS promedio
FROM productos p
JOIN categorias c ON p.categoria_id = c.id
GROUP BY c.id, c.nombre;
```

**Plan de ejecuci√≥n:**
```
 HashAggregate  (cost=15.49..15.69 rows=16 width=262) (actual time=5.165..5.244 rows=3 loops=1)
   Group Key: c.id
   Batches: 1  Memory Usage: 24kB
   ->  Hash Join  (cost=1.36..15.37 rows=16 width=242) (actual time=2.019..2.057 rows=16 loops=1)
         Hash Cond: (c.id = p.categoria_id)
         ->  Seq Scan on categorias c  (cost=0.00..12.80 rows=280 width=222) (actual time=0.318..0.346 rows=5 loops=1)
         ->  Hash  (cost=1.16..1.16 rows=16 width=24) (actual time=1.551..1.554 rows=16 loops=1)
               Buckets: 1024  Batches: 1  Memory Usage: 9kB
               ->  Seq Scan on productos p  (cost=0.00..1.16 rows=16 width=24) (actual time=1.370..1.377 rows=16 loops=1)
 Planning Time: 36.162 ms
 Execution Time: 10.501 ms
(11 rows)
```

**An√°lisis:** El √≠ndice `idx_productos_categoria_id` permite que el HashJoin se ejecute en 1.546ms total. Sin √©l, se necesitar√≠a un Seq Scan completo de productos por cada categor√≠a. Con solo 16 productos, el impacto es m√≠nimo, pero en tablas grandes este √≠ndice es cr√≠tico.

### Evidencia 2: √ìrdenes con Usuarios

**Comando:**
```sql
EXPLAIN ANALYZE
SELECT p.nombre, SUM(od.cantidad) AS vendidos, SUM(od.subtotal) AS ingresos
FROM productos p
JOIN orden_detalles od ON p.id = od.producto_id
GROUP BY p.id, p.nombre;
```

**Plan de ejecuci√≥n:**
```
 HashAggregate  (cost=2.59..2.73 rows=11 width=462) (actual time=1.260..1.266 rows=10 loops=1)
   Group Key: p.id
   Batches: 1  Memory Usage: 24kB
   ->  Hash Join  (cost=1.36..2.51 rows=11 width=442) (actual time=1.190..1.197 rows=11 loops=1)
         Hash Cond: (od.producto_id = p.id)
         ->  Seq Scan on orden_detalles od  (cost=0.00..1.11 rows=11 width=24) (actual time=1.115..1.117 rows=11 loops=1)
         ->  Hash  (cost=1.16..1.16 rows=16 width=422) (actual time=0.047..0.048 rows=16 loops=1)
               Buckets: 1024  Batches: 1  Memory Usage: 9kB
               ->  Seq Scan on productos p  (cost=0.00..1.16 rows=16 width=422) (actual time=0.014..0.016 rows=16 loops=1)
 Planning Time: 8.874 ms
 Execution Time: 1.420 ms
(11 rows)
```

**An√°lisis:** El √≠ndice `idx_ordenes_usuario_id` optimiza el LEFT JOIN. El optimizer elige HashJoin (cost 12.47) en lugar de Nested Loop. Execution Time de 3.132ms es eficiente incluso con la aggregaci√≥n por producto.

## Trade-offs (SQL vs Next.js)

- ‚úÖ **C√°lculos agregados y rankings se hacen en SQL** para evitar mover grandes vol√∫menes de datos al frontend
- ‚úÖ **Filtros se aplican en SQL con par√°metros validados** para mantener seguridad y rendimiento
- ‚úÖ **KPIs b√°sicos** (totales, promedios) se calculan en Server Components para simplificar la UI
- ‚úÖ **Views contienen l√≥gica compleja** (CTE, Window Functions) que es m√°s eficiente en BD

## Threat Model

1. **SQL Injection:** Prevenido con queries parametrizadas y validaci√≥n con Zod en la app
2. **Exposici√≥n de credenciales:** No se exponen al cliente; solo Server Components/acciones en servidor
3. **Permisos excesivos:** Usuario `tarea6` tiene SELECT ONLY en las 5 vistas, sin acceso a tablas base
4. **Variables sensibles:** `.env` queda en `.gitignore`; solo `.env.example` versionado

## Verificaci√≥n r√°pida

Ejecutar consultas de verificaci√≥n en la BD:

```bash
# Dentro del contenedor Postgres
docker exec tarea6_postgres psql -U postgres -d actividad_db -f /docker-entrypoint-initdb.d/verify.sql
```

O desde la m√°quina local (si psql est√° instalado):

```bash
psql -h localhost -U postgres -d actividad_db -p 5433 -f db/verify.sql
```

## Notas de desarrollo

- **Cambios en `.env`:** Requiere `docker compose down -v` + `docker compose up --build`
- **Hot reload en Next.js:** Autom√°tico con volumes en docker-compose
- **pgAdmin:** Excelente para queries ad-hoc y debugging; ya configurado en compose- **Logs:** Usa `docker compose logs -f` para todas las salidas o `docker compose logs -f app` para solo la app

## üêõ Troubleshooting

### Error: "bad interpreter" o "No such file or directory"

**Causa:** El archivo `db/00_init.sh` tiene saltos de l√≠nea de Windows (CRLF) en lugar de Unix (LF).

**Soluci√≥n:**
```bash
# macOS/Linux:
dos2unix db/00_init.sh

# O manualmente (funciona en cualquier sistema):
# PowerShell (Windows):
(Get-Content db/00_init.sh -Raw) -replace "`r`n", "`n" | Set-Content db/00_init.sh

# Bash (Windows con Git Bash):
sed -i 's/\r$//' db/00_init.sh
```

Luego reinicia:
```bash
docker compose down -v
docker compose up --build
```

**Prevenci√≥n:** El archivo `.gitattributes` deber√≠a prevenir esto autom√°ticamente en clones futuros.

---

### Error: "password authentication failed for user"

**Causa:** Las variables de entorno no se est√°n cargando desde `.env`.

**Soluci√≥n:**
1. Verifica que `.env` existe:
   ```bash
   ls -la .env
   ```

2. Si no existe, cr√©alo desde el ejemplo:
   ```bash
   cp .env.example .env
   ```

3. Verifica contenido b√°sico:
   ```bash
   cat .env
   ```

4. Limpia y reinicia:
   ```bash
   docker compose down -v
   docker compose up --build
   ```

---

### Error: "Port already in use"

**Causa:** Los puertos 3000, 5050 o 5433 ya est√°n en uso.

**Soluci√≥n:** Edita `.env` y cambia los puertos:
```env
DB_PORT=5434          # Cambiar de 5433
DB_PORT_WEB=3001      # Cambiar de 3000
```

Luego reinicia:
```bash
docker compose down
docker compose up --build
```

---

### Error: "Connection refused"

**Causa:** El contenedor PostgreSQL a√∫n no estu√° listo.

**Soluci√≥n:** El healthcheck espera hasta 30 segundos. Si ves este error:

1. Espera un poco m√°s
2. Verifica logs:
   ```bash
   docker compose logs postgres
   ```

3. Si los logs muestran errores de SQL, ejecuta validaciones:
   ```bash
   bash scripts/validate.sh
   ```

---

### Error: "No arguments provided" en el script validate.sh

**Causa:** El script no tiene permisos de ejecuci√≥n o el shell int√©rprete es incorrecto.

**Soluci√≥n:**
```bash
# Hacer ejecutable
chmod +x scripts/validate.sh

# Ejecutar expl√≠citamente:
bash scripts/validate.sh
```

---

### Database corrupta o mal inicializada

**Causa:** El volumen de Docker tiene datos viejos.

**Soluci√≥n completa:**
```bash
# Detener y ELIMINAR vol√∫menes
docker compose down -v

# Limpiar contenedores residuales (si es necesario)
docker rm -f tarea6_postgres tarea6_app tarea6_pgadmin 2>/dev/null || true

# Reiniciar completamente
docker compose up --build
```

---

### Verificar que todo est√© conectado correctamente

```bash
# Ver si los contenedores est√°n activos
docker compose ps

# Ver logs de postgres
docker compose logs postgres

# Ver logs de app
docker compose logs app

# Entrar a postgres desde la CLI
docker compose exec postgres psql -U postgres -d actividad_db -c "SELECT 1"
```

---

### M√°s informaci√≥n

- Ver `QUICKSTART.md` para gu√≠a r√°pida
- Ver `SECURE_INIT_FLOW.md` para detalles t√©cnicos de seguridad
- Ejecutar `scripts/validate.sh` para diagn√≥stico autom√°tico